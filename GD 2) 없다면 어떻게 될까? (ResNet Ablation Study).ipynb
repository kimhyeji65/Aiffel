{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polish-schedule",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nuclear-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "agricultural-pacific",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorflow가 활용할 GPU가 장착되어 있는지 확인\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-madness",
   "metadata": {},
   "source": [
    "# ResNet block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prescription-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn block 함수\n",
    "def conv_block(input_layer, channel, kernel_size, padding='same', strides=1, activation='relu'):\n",
    "        x = keras.layers.Conv2D(filters=channel,\n",
    "                                kernel_size=kernel_size,\n",
    "                                kernel_initializer='he_normal',\n",
    "                                kernel_regularizer=keras.regularizers.l2(1e-4),\n",
    "                                padding='same',\n",
    "                                strides=strides)(input_layer)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        if activation:\n",
    "            x = keras.layers.Activation(activation)(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "noble-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "#residual block 함수\n",
    "\n",
    "def build_residual_block(input_layer, num_cnn=3, is_50=True, channel=64,block_num=0 ):\n",
    "    \n",
    "    x = input_layer\n",
    "    \n",
    "    #resnet-50\n",
    "    \n",
    "    if is_50:\n",
    "        for i in range(num_cnn):\n",
    "            if i ==0:\n",
    "                shortcut = conv_block(x,channel*4,(1,1), strides=2, activation=None) #shortcut은 gradient가 잘 흐를 수 있도록 도와 줌\n",
    "                x = conv_block(x, channel, (1,1), strides=2)\n",
    "                x = conv_block(x, channel, (3,3))\n",
    "                x = conv_block(x, channel*4, (1,1), activation =None)\n",
    "            else:\n",
    "                shortcut = x\n",
    "                x = conv_block(x,channel,(1,1))\n",
    "                x = conv_block(x,channel,(3,3))\n",
    "                x = conv_block(x, channel*4, (1,1), activation =None)\n",
    "        \n",
    "            x = keras.layers.Add()([x, shortcut])\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    \n",
    "    #resnet-34\n",
    "    \n",
    "    else:\n",
    "        for i in range(num_cnn):\n",
    "            if block_num > 0 and i ==0:\n",
    "                shortcut = conv_block(x, channel, (1,1), strides=2, activation=None)\n",
    "                x = conv_block(x, channel, (3,3), strides=2)\n",
    "                x = conv_block(x, channel, (3,3), activation=None)\n",
    "            else:\n",
    "                shortcut = x\n",
    "                x = conv_block(x, channel, (3,3))\n",
    "                x = conv_block(x, channel, (3,3), activation=None)\n",
    "            \n",
    "            x = keras.layers.Add()([x, shortcut])\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-exhaust",
   "metadata": {},
   "source": [
    "# ResNet-34, ResNet-50 Complete Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "enabling-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(num_cnn_list=[3,4,6,3], \n",
    "                 channel_list=[64,128,256,512],\n",
    "                 input_shape=(32,32,3),\n",
    "                 num_classes=10,\n",
    "                 name='ResNet_50',\n",
    "                 is_50=True,\n",
    "                 activation='softmax'):\n",
    "    #모델을 만들기 전에 config list들이 같은 길이인지 확인\n",
    "    assert len(num_cnn_list) == len(channel_list)\n",
    "    \n",
    "    #input layer\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    #first layer\n",
    "    x = conv_block(input_layer, 64, (7,7), strides =2)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(2,2), strides =2)(x)\n",
    "    \n",
    "    # Residual block(config list들의 길이만큼 반복해서 블록을 생성)\n",
    "    for block_num, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        x = build_residual_block(x, \n",
    "                               num_cnn=num_cnn, \n",
    "                               channel=channel, \n",
    "                               block_num=block_num, \n",
    "                               is_50=is_50)\n",
    "        \n",
    "    x = keras.layers.GlobalAveragePooling2D()(x) #전역 영역의 평균값을 계산\n",
    "    x = keras.layers.Dense(num_classes, \n",
    "                           activation=activation, \n",
    "                           kernel_initializer='he_normal'\n",
    "                          )(x)\n",
    "    \n",
    "    model = keras.Model(inputs=input_layer, outputs=x, name=name)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "english-sally",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet_50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 16, 16, 64)   9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16, 16, 64)   256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16, 16, 64)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 8, 8, 64)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 8, 8, 64)     36928       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 8, 64)     256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 8, 8, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 8, 8, 64)     36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 8, 64)     256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8, 8, 64)     0           batch_normalization_2[0][0]      \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 8, 8, 64)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 64)     36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 64)     256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 64)     36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 8, 64)     256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8, 8, 64)     0           batch_normalization_4[0][0]      \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 8, 64)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 64)     36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 8, 64)     256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 64)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 64)     36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 8, 64)     0           batch_normalization_6[0][0]      \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 64)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 128)    73856       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 128)    512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 4, 4, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 4, 128)    147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 4, 128)    8320        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 128)    512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 4, 128)    512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 4, 4, 128)    0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 4, 4, 128)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 128)    147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4, 4, 128)    512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 4, 4, 128)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 4, 128)    147584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 4, 128)    512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 128)    0           batch_normalization_11[0][0]     \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 4, 128)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 128)    147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 128)    512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 4, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 4, 4, 128)    147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 4, 128)    512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 4, 128)    0           batch_normalization_13[0][0]     \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 128)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 128)    147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 4, 128)    512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 4, 128)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 128)    147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 128)    512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 128)    0           batch_normalization_15[0][0]     \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 128)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 2, 2, 256)    295168      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 2, 2, 256)    1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 2, 2, 256)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 2, 2, 256)    590080      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 2, 2, 256)    33024       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 2, 2, 256)    1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 2, 2, 256)    1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 256)    0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 2, 2, 256)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 2, 2, 256)    590080      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 2, 2, 256)    1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 2, 2, 256)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 2, 2, 256)    590080      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 2, 2, 256)    1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2, 2, 256)    0           batch_normalization_20[0][0]     \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 2, 2, 256)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 2, 2, 256)    590080      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 2, 2, 256)    1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 2, 2, 256)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 2, 2, 256)    590080      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 2, 2, 256)    1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 2, 2, 256)    0           batch_normalization_22[0][0]     \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 2, 2, 256)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 2, 2, 256)    590080      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 2, 2, 256)    1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 2, 2, 256)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 2, 2, 256)    590080      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 2, 2, 256)    1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2, 2, 256)    0           batch_normalization_24[0][0]     \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 2, 2, 256)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 2, 2, 256)    590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 2, 2, 256)    1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 2, 2, 256)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 2, 2, 256)    590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 2, 2, 256)    1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 2, 2, 256)    0           batch_normalization_26[0][0]     \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 2, 2, 256)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 2, 2, 256)    590080      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 2, 2, 256)    1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 2, 2, 256)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 2, 2, 256)    590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 2, 2, 256)    1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 2, 2, 256)    0           batch_normalization_28[0][0]     \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 2, 2, 256)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 1, 1, 512)    1180160     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 1, 1, 512)    2048        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1, 1, 512)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 1, 1, 512)    2359808     activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 1, 1, 512)    131584      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1, 1, 512)    2048        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 1, 1, 512)    2048        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 1, 1, 512)    0           batch_normalization_31[0][0]     \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 1, 1, 512)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 1, 1, 512)    2359808     activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1, 1, 512)    2048        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 1, 1, 512)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 1, 1, 512)    2359808     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1, 1, 512)    2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 1, 1, 512)    0           batch_normalization_33[0][0]     \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 1, 1, 512)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 1, 1, 512)    2359808     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 1, 1, 512)    2048        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 1, 1, 512)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 1, 1, 512)    2359808     activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 1, 1, 512)    2048        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 1, 1, 512)    0           batch_normalization_35[0][0]     \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 1, 1, 512)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           5130        global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 21,315,338\n",
      "Trainable params: 21,298,314\n",
      "Non-trainable params: 17,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_34 = build_resnet(input_shape=(32,32,3), is_50=False)\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "seeing-society",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet_50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 64)   9472        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 64)   256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)     0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 4, 4, 64)     4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 4, 4, 64)     256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 4, 4, 64)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 4, 4, 64)     36928       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 4, 4, 64)     256         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 4, 4, 64)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 4, 4, 256)    16640       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 4, 4, 256)    16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 4, 4, 256)    1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 4, 4, 256)    1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 256)    0           batch_normalization_40[0][0]     \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 4, 4, 256)    0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 4, 4, 64)     16448       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 4, 4, 64)     256         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 4, 4, 64)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 4, 4, 64)     36928       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 4, 4, 64)     256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 4, 4, 64)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 4, 4, 256)    16640       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 4, 4, 256)    1024        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 4, 4, 256)    0           batch_normalization_43[0][0]     \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 256)    0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 4, 4, 64)     16448       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 64)     256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 64)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 4, 4, 64)     36928       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 4, 4, 64)     256         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 4, 4, 256)    16640       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 256)    1024        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 4, 4, 256)    0           batch_normalization_46[0][0]     \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 256)    0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 2, 2, 128)    32896       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 2, 2, 128)    512         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 2, 2, 128)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 2, 2, 128)    147584      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 2, 2, 128)    512         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 2, 2, 128)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 2, 2, 512)    66048       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 2, 2, 512)    131584      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 2, 2, 512)    2048        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 2, 2, 512)    2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 2, 2, 512)    0           batch_normalization_50[0][0]     \n",
      "                                                                 batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 2, 2, 512)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 2, 2, 128)    65664       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 2, 2, 128)    512         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2, 2, 128)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 2, 2, 128)    147584      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 2, 2, 128)    512         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 2, 128)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 2, 2, 512)    66048       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 2, 2, 512)    2048        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 2, 2, 512)    0           batch_normalization_53[0][0]     \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 2, 2, 512)    0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 2, 2, 128)    65664       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 2, 2, 128)    512         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 2, 2, 128)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 2, 2, 128)    147584      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 2, 2, 128)    512         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 2, 2, 128)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 2, 2, 512)    66048       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 2, 2, 512)    2048        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 2, 2, 512)    0           batch_normalization_56[0][0]     \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 2, 2, 512)    0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 2, 2, 128)    65664       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 2, 2, 128)    512         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 2, 2, 128)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 2, 2, 128)    147584      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 2, 2, 128)    512         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 2, 2, 128)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 2, 2, 512)    66048       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 2, 2, 512)    2048        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 2, 2, 512)    0           batch_normalization_59[0][0]     \n",
      "                                                                 activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 2, 2, 512)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 1, 1, 256)    131328      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1, 1, 256)    1024        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 1, 1, 256)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 1, 1, 256)    590080      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1, 1, 256)    1024        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 1, 1, 256)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 1, 1, 1024)   263168      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 1, 1, 1024)   525312      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 1, 1, 1024)   4096        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 1, 1, 1024)   4096        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 1, 1, 1024)   0           batch_normalization_63[0][0]     \n",
      "                                                                 batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 1, 1, 1024)   0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 1, 1, 256)    262400      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 1, 1, 256)    1024        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 1, 1, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 1, 1, 256)    590080      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 1, 1, 256)    1024        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 1, 1, 256)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 1, 1, 1024)   263168      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1, 1, 1024)   4096        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 1, 1, 1024)   0           batch_normalization_66[0][0]     \n",
      "                                                                 activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1, 1, 1024)   0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 1, 1, 256)    262400      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 1, 1, 256)    1024        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 1, 1, 256)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 1, 1, 256)    590080      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1, 1, 256)    1024        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 1, 1, 256)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 1, 1, 1024)   263168      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 1, 1, 1024)   4096        conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 1, 1, 1024)   0           batch_normalization_69[0][0]     \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 1, 1, 1024)   0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 1, 1, 256)    262400      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 1, 1, 256)    1024        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 1, 1, 256)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 1, 1, 256)    590080      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 1, 1, 256)    1024        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 1, 1, 256)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 1, 1, 1024)   263168      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 1, 1, 1024)   4096        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 1, 1, 1024)   0           batch_normalization_72[0][0]     \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 1, 1, 1024)   0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 1, 1, 256)    262400      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1, 1, 256)    1024        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 1, 1, 256)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 1, 1, 256)    590080      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1, 1, 256)    1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 1, 1, 256)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 1, 1, 1024)   263168      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 1, 1, 1024)   4096        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 1, 1, 1024)   0           batch_normalization_75[0][0]     \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 1, 1, 1024)   0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 1, 1, 256)    262400      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 1, 1, 256)    1024        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 1, 1, 256)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 1, 1, 256)    590080      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 1, 1, 256)    1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 1, 1, 256)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 1, 1, 1024)   263168      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 1, 1, 1024)   4096        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 1, 1, 1024)   0           batch_normalization_78[0][0]     \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 1, 1, 1024)   0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 1, 1, 512)    524800      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 1, 1, 512)    2048        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 1, 1, 512)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 1, 1, 512)    2359808     activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 1, 1, 512)    2048        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 1, 1, 512)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 1, 1, 2048)   2099200     activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 1, 1, 2048)   8192        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 1, 1, 2048)   8192        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 1, 1, 2048)   0           batch_normalization_82[0][0]     \n",
      "                                                                 batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 1, 1, 2048)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 1, 1, 512)    1049088     activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 1, 1, 512)    2048        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 1, 1, 512)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 1, 1, 512)    2359808     activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 1, 1, 512)    2048        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 1, 1, 512)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 1, 1, 2048)   8192        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 1, 1, 2048)   0           batch_normalization_85[0][0]     \n",
      "                                                                 activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 1, 1, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 1, 1, 512)    1049088     activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 1, 1, 512)    2048        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 1, 1, 512)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 1, 1, 512)    2359808     activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 1, 1, 512)    2048        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 1, 1, 512)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 1, 1, 2048)   8192        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 1, 1, 2048)   0           batch_normalization_88[0][0]     \n",
      "                                                                 activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 1, 1, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           20490       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_50 = build_resnet(input_shape=(32,32,3), is_50=True)\n",
    "resnet_50.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-giant",
   "metadata": {},
   "source": [
    "# Plain network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "institutional-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plain block 함수\n",
    "\n",
    "def build_plain_block(input_layer, \n",
    "                      num_cnn=3, \n",
    "                      channel=64, \n",
    "                      block_num=0, \n",
    "                      is_50=True):\n",
    "    \n",
    "    x = input_layer\n",
    "    \n",
    "    # plain-50\n",
    "    if is_50:\n",
    "        for i in range(num_cnn):\n",
    "            if block_num > 0 and i == 0:\n",
    "                x = conv_block(x, channel, (1,1), strides=2)\n",
    "                x = conv_block(x, channel, (3,3))\n",
    "                x = conv_block(x, channel*4, (1,1))\n",
    "            else:\n",
    "                x = conv_block(x, channel, (1,1))\n",
    "                x = conv_block(x, channel, (3,3))\n",
    "                x = conv_block(x, channel*4, (1,1))\n",
    "    \n",
    "    # plain-34\n",
    "    else:\n",
    "        for i in range(num_cnn):\n",
    "            if block_num > 0 and i == 0:\n",
    "                x = conv_block(x, channel, (3,3), strides=2)\n",
    "                x = conv_block(x, channel, (3,3))\n",
    "            else:\n",
    "                x = conv_block(x, channel, (3,3))\n",
    "                x = conv_block(x, channel, (3,3))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mysterious-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_plain(num_cnn_list=[3,4,6,3], \n",
    "                   channel_list=[64,128,256,512],\n",
    "                   input_shape=(32,32,3),\n",
    "                   num_classes=10,\n",
    "                   name='Plain_50',\n",
    "                   is_50=True,\n",
    "                   activation='softmax'):\n",
    "    #모델을 만들기 전에 config list들이 같은 길이인지 확인\n",
    "    assert len(num_cnn_list) == len(channel_list)\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape, name='Input')\n",
    "    \n",
    "   \n",
    "    #first layer\n",
    "    x = conv_block(input_layer, 64, (7,7), strides =2)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(2,2), strides =2)(x)\n",
    "    \n",
    "    # Residual block(config list들의 길이만큼 반복해서 블록을 생성)\n",
    "    for block_num, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        x = build_plain_block(x, \n",
    "                              num_cnn=num_cnn, \n",
    "                              channel=channel, \n",
    "                              block_num=block_num, \n",
    "                              is_50=is_50)\n",
    "        \n",
    "    x = keras.layers.GlobalAveragePooling2D()(x) #전역 영역의 평균값을 계산\n",
    "    x = keras.layers.Dense(num_classes, \n",
    "                           activation=activation, \n",
    "                           kernel_initializer='he_normal'\n",
    "                          )(x)\n",
    "    \n",
    "    model = keras.Model(inputs=input_layer, outputs=x, name=name)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "played-sucking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Plain_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 112, 112, 64)      9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 14, 14, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_116 (Conv2D)          (None, 7, 7, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_117 (Conv2D)          (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 21,138,826\n",
      "Trainable params: 21,123,594\n",
      "Non-trainable params: 15,232\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#PlainNet 34\n",
    "plain_34 = build_plain(is_50=False,\n",
    "                       input_shape=(224,224,3))\n",
    "plain_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sharp-highland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Plain_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 112, 112, 64)      9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 56, 56, 64)        4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 56, 56, 256)       16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 56, 56, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_126 (Bat (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_127 (Bat (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_128 (Conv2D)          (None, 56, 56, 256)       16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_128 (Bat (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 56, 56, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_129 (Bat (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_130 (Bat (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 56, 56, 256)       16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_131 (Bat (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 28, 28, 128)       32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_132 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_133 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_133 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 28, 28, 512)       66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_134 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 28, 28, 128)       65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_135 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_136 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_136 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 28, 28, 512)       66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_137 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 28, 28, 128)       65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_138 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_139 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_140 (Conv2D)          (None, 28, 28, 512)       66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_140 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_141 (Conv2D)          (None, 28, 28, 128)       65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_141 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_142 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_142 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_143 (Conv2D)          (None, 28, 28, 512)       66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_143 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_144 (Conv2D)          (None, 14, 14, 256)       131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_144 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_145 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_145 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_146 (Conv2D)          (None, 14, 14, 1024)      263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_146 (Bat (None, 14, 14, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_147 (Conv2D)          (None, 14, 14, 256)       262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_147 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_148 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_148 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_149 (Conv2D)          (None, 14, 14, 1024)      263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_149 (Bat (None, 14, 14, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_150 (Conv2D)          (None, 14, 14, 256)       262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_150 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_151 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_151 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_152 (Conv2D)          (None, 14, 14, 1024)      263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_152 (Bat (None, 14, 14, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_153 (Conv2D)          (None, 14, 14, 256)       262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_153 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_154 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_154 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_155 (Conv2D)          (None, 14, 14, 1024)      263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_155 (Bat (None, 14, 14, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_156 (Conv2D)          (None, 14, 14, 256)       262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_156 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_157 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_157 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_158 (Conv2D)          (None, 14, 14, 1024)      263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_158 (Bat (None, 14, 14, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_159 (Conv2D)          (None, 14, 14, 256)       262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_159 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_160 (Conv2D)          (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_160 (Bat (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_161 (Conv2D)          (None, 14, 14, 1024)      263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_161 (Bat (None, 14, 14, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_162 (Conv2D)          (None, 7, 7, 512)         524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_162 (Bat (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_163 (Conv2D)          (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_163 (Bat (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_164 (Conv2D)          (None, 7, 7, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "batch_normalization_164 (Bat (None, 7, 7, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 7, 7, 2048)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_165 (Conv2D)          (None, 7, 7, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_165 (Bat (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_166 (Conv2D)          (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_166 (Bat (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_167 (Conv2D)          (None, 7, 7, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "batch_normalization_167 (Bat (None, 7, 7, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 7, 7, 2048)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_168 (Conv2D)          (None, 7, 7, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_168 (Bat (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_169 (Conv2D)          (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_169 (Bat (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_170 (Conv2D)          (None, 7, 7, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "batch_normalization_170 (Bat (None, 7, 7, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 7, 7, 2048)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 20,820,106\n",
      "Trainable params: 20,774,666\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#PlainNet50\n",
    "plain_50 = build_plain(is_50=True,\n",
    "                       input_shape=(224,224,3)\n",
    "                       )\n",
    "plain_50.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-confusion",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "thrown-brand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 786.68 MiB (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9786e8f9054d64823297bf16568eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790036b4983b43eda39cd5c079ef2edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/23262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:1738 images were corrupted and were skipped\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling cats_vs_dogs-train.tfrecord...:   0%|          | 0/23262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cats_vs_dogs downloaded and prepared to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Dataset\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "#tfds.disable_progress_bar()   # 이 주석을 풀면 데이터셋 다운로드과정의 프로그레스바가 나타나지 않습니다.\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:]'],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "objective-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeaturesDict({\n",
      "    'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
      "    'image/filename': Text(shape=(), dtype=tf.string),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds_info.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prescribed-contest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18610, shape=(), dtype=int64)\n",
      "tf.Tensor(4652, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.data.experimental.cardinality(ds_train))\n",
    "print(tf.data.experimental.cardinality(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fluid-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "#머신러닝:scale이 큰 feature의 영향 커짐 방지 , 딥러닝:Local optimum에 빠질 위험 감소(학습 속도 향상)\n",
    "def normalize_and_resize_img(image, label):\n",
    "    image = tf.image.resize(image, (224,224)) # resize\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "explicit-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img, \n",
    "        num_parallel_calls=1\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "typical-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "noticed-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = apply_normalize_on_dataset(ds_train, batch_size=BATCH_SIZE)\n",
    "ds_test = apply_normalize_on_dataset(ds_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-fiction",
   "metadata": {},
   "source": [
    "# ResNet-50 vs Plain-50 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "italian-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet_50 일 때 is_50=True \n",
    "resnet_50 = build_resnet(num_cnn_list = [3, 4, 6, 3],\n",
    "                         channel_list=[64, 128, 256, 512],\n",
    "                         is_50=True,\n",
    "                         num_classes=1,\n",
    "                         input_shape=(224,224,3),\n",
    "                         name='ResNet_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "needed-reggae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "581/581 [==============================] - 230s 320ms/step - loss: 6.2978 - accuracy: 0.4976 - val_loss: 1.5812 - val_accuracy: 0.5026\n",
      "Epoch 2/20\n",
      "581/581 [==============================] - 203s 350ms/step - loss: 1.4586 - accuracy: 0.4963 - val_loss: 1.2833 - val_accuracy: 0.5136\n",
      "Epoch 3/20\n",
      "581/581 [==============================] - 170s 293ms/step - loss: 1.2290 - accuracy: 0.4957 - val_loss: 3.5607 - val_accuracy: 0.5054\n",
      "Epoch 4/20\n",
      "581/581 [==============================] - 170s 292ms/step - loss: 1.0071 - accuracy: 0.5033 - val_loss: 0.8349 - val_accuracy: 0.5133\n",
      "Epoch 5/20\n",
      "581/581 [==============================] - 170s 292ms/step - loss: 0.8409 - accuracy: 0.4986 - val_loss: 0.8029 - val_accuracy: 0.5089\n",
      "Epoch 6/20\n",
      "581/581 [==============================] - 170s 293ms/step - loss: 0.7869 - accuracy: 0.4968 - val_loss: 0.7844 - val_accuracy: 0.5078\n",
      "Epoch 7/20\n",
      "581/581 [==============================] - 170s 293ms/step - loss: 0.7427 - accuracy: 0.4971 - val_loss: 1.2491 - val_accuracy: 0.5121\n",
      "Epoch 8/20\n",
      "581/581 [==============================] - 170s 293ms/step - loss: 0.7632 - accuracy: 0.4950 - val_loss: 0.8017 - val_accuracy: 0.5119\n",
      "Epoch 9/20\n",
      "581/581 [==============================] - 170s 293ms/step - loss: 0.7219 - accuracy: 0.5020 - val_loss: 0.7364 - val_accuracy: 0.5246\n",
      "Epoch 10/20\n",
      "581/581 [==============================] - 171s 295ms/step - loss: 0.7135 - accuracy: 0.4972 - val_loss: 0.9573 - val_accuracy: 0.5170\n",
      "Epoch 11/20\n",
      "581/581 [==============================] - 170s 293ms/step - loss: 0.7115 - accuracy: 0.5034 - val_loss: 0.7527 - val_accuracy: 0.5110\n",
      "Epoch 12/20\n",
      "581/581 [==============================] - 171s 294ms/step - loss: 0.7044 - accuracy: 0.4994 - val_loss: 1.1370 - val_accuracy: 0.5125\n",
      "Epoch 13/20\n",
      "581/581 [==============================] - 171s 295ms/step - loss: 0.6775 - accuracy: 0.4984 - val_loss: 1.3448 - val_accuracy: 0.5110\n",
      "Epoch 14/20\n",
      "581/581 [==============================] - 170s 293ms/step - loss: 0.6566 - accuracy: 0.4963 - val_loss: 1.3510 - val_accuracy: 0.5050\n",
      "Epoch 15/20\n",
      "581/581 [==============================] - 170s 293ms/step - loss: 0.6292 - accuracy: 0.4936 - val_loss: 0.7172 - val_accuracy: 0.5175\n",
      "Epoch 16/20\n",
      "581/581 [==============================] - 170s 292ms/step - loss: 0.6134 - accuracy: 0.4938 - val_loss: 0.7548 - val_accuracy: 0.5201\n",
      "Epoch 17/20\n",
      "581/581 [==============================] - 169s 292ms/step - loss: 0.6070 - accuracy: 0.4900 - val_loss: 0.8172 - val_accuracy: 0.5162\n",
      "Epoch 18/20\n",
      "581/581 [==============================] - 170s 292ms/step - loss: 0.5934 - accuracy: 0.4968 - val_loss: 0.7443 - val_accuracy: 0.5139\n",
      "Epoch 19/20\n",
      "581/581 [==============================] - 170s 292ms/step - loss: 0.5875 - accuracy: 0.4979 - val_loss: 0.7314 - val_accuracy: 0.5058\n",
      "Epoch 20/20\n",
      "581/581 [==============================] - 171s 294ms/step - loss: 0.5999 - accuracy: 0.4976 - val_loss: 0.7516 - val_accuracy: 0.5088\n"
     ]
    }
   ],
   "source": [
    "resnet_50.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.01), #momentum=0.9\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "history_resnet_50 = resnet_50.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "gentle-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_50 = build_plain(num_cnn_list = [3, 4, 6, 3],\n",
    "                         channel_list=[64, 128, 256, 512],\n",
    "                         is_50=True,\n",
    "                         num_classes=1,\n",
    "                         input_shape=(224,224,3),\n",
    "                         name='Plain_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "royal-things",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "581/581 [==============================] - 426s 651ms/step - loss: 5.0388 - accuracy: 0.4964 - val_loss: 2.5260 - val_accuracy: 0.5093\n",
      "Epoch 2/20\n",
      "581/581 [==============================] - 394s 679ms/step - loss: 1.9277 - accuracy: 0.4982 - val_loss: 1.3027 - val_accuracy: 0.5229\n",
      "Epoch 3/20\n",
      "581/581 [==============================] - 360s 619ms/step - loss: 1.2479 - accuracy: 0.4966 - val_loss: 1.0763 - val_accuracy: 0.4974\n",
      "Epoch 4/20\n",
      "581/581 [==============================] - 360s 620ms/step - loss: 1.0696 - accuracy: 0.5006 - val_loss: 1.0154 - val_accuracy: 0.5177\n",
      "Epoch 5/20\n",
      "581/581 [==============================] - 361s 621ms/step - loss: 1.0006 - accuracy: 0.4933 - val_loss: 1.3419 - val_accuracy: 0.5136\n",
      "Epoch 6/20\n",
      "581/581 [==============================] - 360s 620ms/step - loss: 1.0200 - accuracy: 0.5031 - val_loss: 0.8220 - val_accuracy: 0.5149\n",
      "Epoch 7/20\n",
      "581/581 [==============================] - 362s 623ms/step - loss: 0.9959 - accuracy: 0.4970 - val_loss: 0.9734 - val_accuracy: 0.5067\n",
      "Epoch 8/20\n",
      "581/581 [==============================] - 359s 618ms/step - loss: 0.8622 - accuracy: 0.5010 - val_loss: 8226279.5000 - val_accuracy: 0.4991\n",
      "Epoch 9/20\n",
      "581/581 [==============================] - 359s 617ms/step - loss: 1.0113 - accuracy: 0.4889 - val_loss: 0.8570 - val_accuracy: 0.5087\n",
      "Epoch 10/20\n",
      "581/581 [==============================] - 361s 621ms/step - loss: 0.7792 - accuracy: 0.4946 - val_loss: 10.4938 - val_accuracy: 0.5171\n",
      "Epoch 11/20\n",
      "581/581 [==============================] - 360s 620ms/step - loss: 0.9264 - accuracy: 0.4958 - val_loss: 5.2131 - val_accuracy: 0.5136\n",
      "Epoch 12/20\n",
      "581/581 [==============================] - 358s 616ms/step - loss: 0.8613 - accuracy: 0.4972 - val_loss: 0.7853 - val_accuracy: 0.5214\n",
      "Epoch 13/20\n",
      "581/581 [==============================] - 358s 616ms/step - loss: 0.7874 - accuracy: 0.5027 - val_loss: 0.7823 - val_accuracy: 0.5149\n",
      "Epoch 14/20\n",
      "581/581 [==============================] - 356s 613ms/step - loss: 0.7514 - accuracy: 0.4985 - val_loss: 0.7657 - val_accuracy: 0.5158\n",
      "Epoch 15/20\n",
      "581/581 [==============================] - 357s 614ms/step - loss: 0.7746 - accuracy: 0.5041 - val_loss: 1.0026 - val_accuracy: 0.5160\n",
      "Epoch 16/20\n",
      "581/581 [==============================] - 359s 617ms/step - loss: 0.8343 - accuracy: 0.4985 - val_loss: 0.9014 - val_accuracy: 0.5200\n",
      "Epoch 17/20\n",
      "581/581 [==============================] - 358s 617ms/step - loss: 0.9031 - accuracy: 0.4990 - val_loss: 0.9378 - val_accuracy: 0.5138\n",
      "Epoch 18/20\n",
      "581/581 [==============================] - 355s 610ms/step - loss: 0.8615 - accuracy: 0.4916 - val_loss: 0.8088 - val_accuracy: 0.5117\n",
      "Epoch 19/20\n",
      "581/581 [==============================] - 358s 617ms/step - loss: 0.7677 - accuracy: 0.4964 - val_loss: 0.8507 - val_accuracy: 0.5067\n",
      "Epoch 20/20\n",
      "581/581 [==============================] - 356s 613ms/step - loss: 0.8693 - accuracy: 0.4940 - val_loss: 0.8043 - val_accuracy: 0.5123\n"
     ]
    }
   ],
   "source": [
    "plain_50.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_plain_50 = plain_50.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "accomplished-sapphire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\n\\nplt.figure(figsize=(15,5))\\nplt.subplot(1,2,1)\\nplt.plot(history_resnet_50.history['loss'],'b')\\nplt.plot(history_plain_50.history['loss'],'g')\\nplt.title('training loss')\\nplt.ylabel('Loss')\\nplt.xlabel('Epoch')\\nplt.legend(['ResNet_50', 'Plain_50'], loc='upper right')\\n\\nplt.subplot(1, 2, 2)\\nplt.plot(history_resnet_50.history['val_accuracy'], 'r')\\nplt.plot(history_plain_50.history['val_accuracy'], 'm')\\nplt.title('validation accuracy')\\nplt.ylabel('Accuracy')\\nplt.xlabel('Epoch')\\nplt.legend(['ResNet_50', 'Plain_50'], loc='lower right')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualization\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_resnet_50.history['loss'],'b')\n",
    "plt.plot(history_plain_50.history['loss'],'g')\n",
    "plt.title('training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['ResNet_50', 'Plain_50'], loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_resnet_50.history['val_accuracy'], 'r')\n",
    "plt.plot(history_plain_50.history['val_accuracy'], 'm')\n",
    "plt.title('validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['ResNet_50', 'Plain_50'], loc='lower right')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-plymouth",
   "metadata": {},
   "source": [
    "# ResNet-34 vs Plain-34 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "understood-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_34 = build_resnet(num_cnn_list = [3, 4, 6, 3],\n",
    "                         channel_list=[64, 128, 256, 512],\n",
    "                         is_50=False,\n",
    "                         num_classes=1,\n",
    "                         input_shape=(224,224,3),\n",
    "                         name='ResNet_34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "velvet-recording",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "581/581 [==============================] - 272s 420ms/step - loss: 3.4196 - accuracy: 0.4944 - val_loss: 0.8817 - val_accuracy: 0.5084\n",
      "Epoch 2/20\n",
      "581/581 [==============================] - 249s 429ms/step - loss: 0.9588 - accuracy: 0.4998 - val_loss: 1.0765 - val_accuracy: 0.5175\n",
      "Epoch 3/20\n",
      "581/581 [==============================] - 234s 403ms/step - loss: 0.8774 - accuracy: 0.5002 - val_loss: 1.2788 - val_accuracy: 0.5206\n",
      "Epoch 4/20\n",
      "581/581 [==============================] - 234s 402ms/step - loss: 0.9493 - accuracy: 0.4988 - val_loss: 0.8541 - val_accuracy: 0.5080\n",
      "Epoch 5/20\n",
      "581/581 [==============================] - 233s 402ms/step - loss: 0.7742 - accuracy: 0.5023 - val_loss: 0.7737 - val_accuracy: 0.5157\n",
      "Epoch 6/20\n",
      "581/581 [==============================] - 234s 402ms/step - loss: 0.8205 - accuracy: 0.4934 - val_loss: 0.7191 - val_accuracy: 0.5102\n",
      "Epoch 7/20\n",
      "581/581 [==============================] - 234s 403ms/step - loss: 0.7418 - accuracy: 0.4988 - val_loss: 0.7137 - val_accuracy: 0.5154\n",
      "Epoch 8/20\n",
      "581/581 [==============================] - 234s 402ms/step - loss: 0.7183 - accuracy: 0.5030 - val_loss: 0.7317 - val_accuracy: 0.5039\n",
      "Epoch 9/20\n",
      "581/581 [==============================] - 234s 403ms/step - loss: 0.7386 - accuracy: 0.5049 - val_loss: 0.7162 - val_accuracy: 0.5149\n",
      "Epoch 10/20\n",
      "581/581 [==============================] - 233s 401ms/step - loss: 0.7203 - accuracy: 0.4961 - val_loss: 0.7341 - val_accuracy: 0.5119\n",
      "Epoch 11/20\n",
      "581/581 [==============================] - 233s 401ms/step - loss: 0.7270 - accuracy: 0.4999 - val_loss: 0.7290 - val_accuracy: 0.5102\n",
      "Epoch 12/20\n",
      "581/581 [==============================] - 233s 401ms/step - loss: 0.7553 - accuracy: 0.5009 - val_loss: 0.8104 - val_accuracy: 0.5125\n",
      "Epoch 13/20\n",
      "581/581 [==============================] - 233s 401ms/step - loss: 0.7445 - accuracy: 0.4973 - val_loss: 1.9177 - val_accuracy: 0.5193\n",
      "Epoch 14/20\n",
      "581/581 [==============================] - 233s 401ms/step - loss: 0.7279 - accuracy: 0.4963 - val_loss: 0.7140 - val_accuracy: 0.5133\n",
      "Epoch 15/20\n",
      "581/581 [==============================] - 233s 401ms/step - loss: 0.7231 - accuracy: 0.4991 - val_loss: 0.7056 - val_accuracy: 0.5126\n",
      "Epoch 16/20\n",
      "581/581 [==============================] - 233s 400ms/step - loss: 0.7290 - accuracy: 0.4964 - val_loss: 0.7430 - val_accuracy: 0.5207\n",
      "Epoch 17/20\n",
      "581/581 [==============================] - 232s 400ms/step - loss: 0.7212 - accuracy: 0.5031 - val_loss: 1.9549 - val_accuracy: 0.5138\n",
      "Epoch 18/20\n",
      "581/581 [==============================] - 234s 402ms/step - loss: 0.7251 - accuracy: 0.4971 - val_loss: 0.7413 - val_accuracy: 0.5026\n",
      "Epoch 19/20\n",
      "581/581 [==============================] - 232s 400ms/step - loss: 0.7128 - accuracy: 0.4954 - val_loss: 0.7295 - val_accuracy: 0.5147\n",
      "Epoch 20/20\n",
      "581/581 [==============================] - 233s 402ms/step - loss: 0.7306 - accuracy: 0.4997 - val_loss: 0.7954 - val_accuracy: 0.5117\n"
     ]
    }
   ],
   "source": [
    "resnet_34.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_resnet_34 = resnet_34.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "accepted-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_34 = build_plain(num_cnn_list = [3, 4, 6, 3],\n",
    "                         channel_list=[64, 128, 256, 512],\n",
    "                         is_50=False,\n",
    "                         num_classes=1,\n",
    "                         input_shape=(224,224,3),\n",
    "                         name='Plain_34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hawaiian-track",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "581/581 [==============================] - 237s 388ms/step - loss: 2.9040 - accuracy: 0.4988 - val_loss: 1.0131 - val_accuracy: 0.5002\n",
      "Epoch 2/20\n",
      "581/581 [==============================] - 224s 386ms/step - loss: 1.0407 - accuracy: 0.4988 - val_loss: 0.8799 - val_accuracy: 0.5244\n",
      "Epoch 3/20\n",
      "581/581 [==============================] - 224s 385ms/step - loss: 0.9726 - accuracy: 0.4939 - val_loss: 0.7904 - val_accuracy: 0.5152\n",
      "Epoch 4/20\n",
      "581/581 [==============================] - 224s 386ms/step - loss: 0.8545 - accuracy: 0.5005 - val_loss: 0.8668 - val_accuracy: 0.5110\n",
      "Epoch 5/20\n",
      "581/581 [==============================] - 224s 386ms/step - loss: 0.8801 - accuracy: 0.5058 - val_loss: 0.7064 - val_accuracy: 0.5116\n",
      "Epoch 6/20\n",
      "581/581 [==============================] - 224s 386ms/step - loss: 0.8427 - accuracy: 0.4915 - val_loss: 0.7695 - val_accuracy: 0.5039\n",
      "Epoch 7/20\n",
      "581/581 [==============================] - 224s 386ms/step - loss: 0.8229 - accuracy: 0.4964 - val_loss: 680.3577 - val_accuracy: 0.5113\n",
      "Epoch 8/20\n",
      "581/581 [==============================] - 224s 385ms/step - loss: 0.8992 - accuracy: 0.4990 - val_loss: 0.7414 - val_accuracy: 0.4983\n",
      "Epoch 9/20\n",
      "581/581 [==============================] - 224s 386ms/step - loss: 0.7774 - accuracy: 0.4978 - val_loss: 0.7310 - val_accuracy: 0.5173\n",
      "Epoch 10/20\n",
      "581/581 [==============================] - 225s 387ms/step - loss: 0.7357 - accuracy: 0.4981 - val_loss: 0.7922 - val_accuracy: 0.5078\n",
      "Epoch 11/20\n",
      "581/581 [==============================] - 224s 385ms/step - loss: 0.8299 - accuracy: 0.5007 - val_loss: 766.4192 - val_accuracy: 0.5065\n",
      "Epoch 12/20\n",
      "581/581 [==============================] - 223s 385ms/step - loss: 1.0029 - accuracy: 0.4981 - val_loss: 12.2703 - val_accuracy: 0.4929\n",
      "Epoch 13/20\n",
      "581/581 [==============================] - 223s 384ms/step - loss: 0.8036 - accuracy: 0.4974 - val_loss: 1.0009 - val_accuracy: 0.5177\n",
      "Epoch 14/20\n",
      "581/581 [==============================] - 223s 384ms/step - loss: 0.8635 - accuracy: 0.4990 - val_loss: 0.7316 - val_accuracy: 0.5214\n",
      "Epoch 15/20\n",
      "581/581 [==============================] - 223s 384ms/step - loss: 0.8654 - accuracy: 0.5010 - val_loss: 0.8023 - val_accuracy: 0.5134\n",
      "Epoch 16/20\n",
      "581/581 [==============================] - 222s 383ms/step - loss: 0.8059 - accuracy: 0.4979 - val_loss: 0.8444 - val_accuracy: 0.5167\n",
      "Epoch 17/20\n",
      "581/581 [==============================] - 222s 383ms/step - loss: 0.8160 - accuracy: 0.4970 - val_loss: 0.7579 - val_accuracy: 0.5155\n",
      "Epoch 18/20\n",
      "581/581 [==============================] - 222s 382ms/step - loss: 0.7616 - accuracy: 0.4985 - val_loss: 0.7333 - val_accuracy: 0.5043\n",
      "Epoch 19/20\n",
      "581/581 [==============================] - 222s 382ms/step - loss: 0.7861 - accuracy: 0.4994 - val_loss: 0.7830 - val_accuracy: 0.5082\n",
      "Epoch 20/20\n",
      "581/581 [==============================] - 222s 382ms/step - loss: 0.7893 - accuracy: 0.4915 - val_loss: 1758.1377 - val_accuracy: 0.5141\n"
     ]
    }
   ],
   "source": [
    "plain_34.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_plain_34 = plain_34.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "mature-professional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(15,5))\\nplt.subplot(1,2,1)\\nplt.plot(history_resnet_34.history['loss'],'b')\\nplt.plot(history_plain_34.history['loss'],'g')\\nplt.title('training loss')\\nplt.ylabel('Loss')\\nplt.xlabel('Epoch')\\nplt.legend(['ResNet_34', 'Plain_34'], loc='upper right')\\n\\nplt.subplot(1, 2, 2)\\nplt.plot(history_resnet_34.history['val_accuracy'], 'r')\\nplt.plot(history_plain_34.history['val_accuracy'], 'm')\\nplt.title('validation accuracy')\\nplt.ylabel('Accuracy')\\nplt.xlabel('Epoch')\\nplt.legend(['ResNet_34', 'Plain_34'], loc='lower right')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualization\n",
    "'''\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_resnet_34.history['loss'],'b')\n",
    "plt.plot(history_plain_34.history['loss'],'g')\n",
    "plt.title('training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['ResNet_34', 'Plain_34'], loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_resnet_34.history['val_accuracy'], 'r')\n",
    "plt.plot(history_plain_34.history['val_accuracy'], 'm')\n",
    "plt.title('validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['ResNet_34', 'Plain_34'], loc='lower right')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-glucose",
   "metadata": {},
   "source": [
    "# 결과 \n",
    "resnet model과 plain을 비교 했을 때 resnet 이 더 나은 결과를 보이고 있다.\n",
    "찾아보니 is_plain과 같이  skip connection(=shortcut)을 하는 법이 있다고 한다 다음에 이용해서 모델을 만들어 봐야겠다.\n",
    "그리고 파라미터를 보는 중에 꼭 optimizer SGD를 사용해야 하는 가 궁금증이 들어서 찾다가 Adam이 SGD 보다 좋은 성능을 낼 수 있다는 것을 알았다.  \n",
    "https://www.sciencedirect.com/science/article/pii/S2405959519303455#fig2\n",
    "      \n",
    "* SGD 사용시 epoch 20이 베스트 하이퍼 파라미터의 조합이라고 한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
